name: PERTI Site Monitor

on:
  schedule:
    - cron: '* * * * *'
  workflow_dispatch:
    inputs:
      force_alert:
        description: 'Force send test alert to Discord'
        type: boolean
        default: false

env:
  SITE_URL: https://perti.vatcscc.org
  TIMEOUT: 10
  SLOW_MS: 2000

jobs:
  monitor:
    runs-on: ubuntu-latest

    steps:
    - name: Check All Endpoints
      id: checks
      env:
        HEALTH_KEY: ${{ secrets.MONITORING_API_KEY }}
      run: |
        check() {
          local name=$1 url=$2 type=$3 accept=${4:-2xx}
          local body="/tmp/body_${name}"

          HDRS=(-H "Accept: application/json")
          [[ -n "$HEALTH_KEY" ]] && HDRS+=(-H "X-API-Key: $HEALTH_KEY")

          local raw
          raw=$(curl -sS -w '%{http_code} %{time_starttransfer} %{time_total} %{size_download}' \
            --max-time "$TIMEOUT" "${HDRS[@]}" -o "$body" "$url" 2>/dev/null) || true

          local code ttfb_s total_s size_raw
          read -r code ttfb_s total_s size_raw <<< "${raw:-000 0 0 0}"
          local ms=$(awk "BEGIN{printf \"%d\", ${total_s:-0} * 1000}")
          local ttfb=$(awk "BEGIN{printf \"%d\", ${ttfb_s:-0} * 1000}")

          local ok=fail
          case "$accept" in
            2xx)      [[ "$code" =~ ^2[0-9][0-9]$ ]] && ok=ok ;;
            2xx+auth) [[ "$code" =~ ^(2[0-9][0-9]|302|401|403)$ ]] && ok=ok ;;
          esac
          [[ "$type" == api && "$ok" == ok ]] && ! jq -e . "$body" &>/dev/null && ok=fail

          jq -nc --arg n "$name" --arg s "$ok" --arg c "$code" \
            --argjson ms "$ms" --argjson ttfb "$ttfb" --arg t "$type" \
            '{name:$n,status:$s,code:$c,ms:$ms,ttfb:$ttfb,type:$t}' > "/tmp/r_${name}"
        }

        # All checks in parallel — total wall time = slowest single request
        check homepage "$SITE_URL/"                              page 2xx      &
        check jatoc    "$SITE_URL/jatoc.php"                     page 2xx      &
        check nod      "$SITE_URL/nod.php"                       page 2xx      &
        check gdt      "$SITE_URL/gdt.php"                       page 2xx+auth &
        check route    "$SITE_URL/route.php"                     page 2xx+auth &
        check stats    "$SITE_URL/api/adl/stats.php"             api  2xx      &
        check flights  "$SITE_URL/api/adl/current.php?limit=5"   api  2xx      &
        check health   "$SITE_URL/api/system/health.php"         api  2xx      &
        check tmi      "$SITE_URL/api/nod/tmi_active.php"        api  2xx      &
        check sstatus  "$SITE_URL/api/stats/status.php"          api  2xx      &
        check realtime "$SITE_URL/api/stats/realtime.php"       api  2xx      &
        wait

        jq -s '.' /tmp/r_* > /tmp/results.json

        # Summary stats
        FAILS=$(jq '[.[]|select(.status=="fail")]|length' /tmp/results.json)
        SLOW=$(jq --argjson t "$SLOW_MS" '[.[]|select(.ms>$t)]|length' /tmp/results.json)
        OK_N=$(jq '[.[]|select(.status=="ok")]|length' /tmp/results.json)
        TOTAL=$(jq 'length' /tmp/results.json)

        read -r AVG_MS MAX_MS AVG_TTFB MAX_TTFB <<< "$(jq -r \
          '[([.[].ms]|add/length|round),([.[].ms]|max),
            ([.[].ttfb]|add/length|round),([.[].ttfb]|max)]|@tsv' /tmp/results.json)"

        {
          echo "failures=$FAILS"; echo "slow=$SLOW"
          echo "ok=$OK_N"; echo "total=$TOTAL"
          echo "avg_ms=$AVG_MS"; echo "max_ms=$MAX_MS"
          echo "avg_ttfb=$AVG_TTFB"; echo "max_ttfb=$MAX_TTFB"
        } >> "$GITHUB_OUTPUT"

        if   (( FAILS >= 5 )); then SEV=CRITICAL
        elif (( FAILS >= 2 )); then SEV=MAJOR
        elif (( FAILS >= 1 )); then SEV=WARNING
        elif (( SLOW  >= 1 )); then SEV=SLOW
        else                        SEV=HEALTHY; fi
        echo "severity=$SEV" >> "$GITHUB_OUTPUT"

        # SSL certificate expiry
        CERT_END=$(echo | timeout 5 openssl s_client -servername perti.vatcscc.org \
          -connect perti.vatcscc.org:443 2>/dev/null \
          | openssl x509 -noout -enddate 2>/dev/null | cut -d= -f2)
        [[ -n "$CERT_END" ]] && echo "cert_days=$(( ($(date -d "$CERT_END" +%s) - $(date +%s)) / 86400 ))" >> "$GITHUB_OUTPUT"

        # Log summary
        jq -r '.[]|"\(.status|if .=="ok" then "ok" else "FAIL" end)\t\(.name)\t\(.code)\t\(.ms)ms\tttfb:\(.ttfb)ms"' \
          /tmp/results.json | column -t
        echo "--- $SEV | $FAILS fail, $SLOW slow | avg ${AVG_MS}ms peak ${MAX_MS}ms ---"

    - name: Load Previous State
      uses: actions/cache@v4
      with:
        path: /tmp/monitor_state
        key: monitor-state-${{ github.run_id }}
        restore-keys: monitor-state-

    - name: Detect State Change
      id: delta
      run: |
        mkdir -p /tmp/monitor_state
        NOW="${{ steps.checks.outputs.severity }}"
        PREV=$(cat /tmp/monitor_state/severity 2>/dev/null || echo HEALTHY)
        COUNT=$(cat /tmp/monitor_state/fail_count 2>/dev/null || echo 0)
        OUTAGE_START=$(cat /tmp/monitor_state/outage_start 2>/dev/null || echo "")

        echo "$NOW" > /tmp/monitor_state/severity

        ALERT=false RECOVERED=false DURATION=""
        if [[ "$NOW" == "HEALTHY" && "$PREV" != "HEALTHY" ]]; then
          ALERT=true; RECOVERED=true; COUNT=0
          [[ -n "$OUTAGE_START" ]] && DURATION=$(( ($(date +%s) - OUTAGE_START) / 60 ))
          rm -f /tmp/monitor_state/outage_start
        elif [[ "$NOW" != "HEALTHY" && "$PREV" == "HEALTHY" ]]; then
          ALERT=true; COUNT=1
          date +%s > /tmp/monitor_state/outage_start
        elif [[ "$NOW" != "HEALTHY" ]]; then
          COUNT=$((COUNT + 1))
          (( COUNT % 15 == 0 )) && ALERT=true  # Reminder every ~15 runs
          [[ -n "$OUTAGE_START" ]] && DURATION=$(( ($(date +%s) - OUTAGE_START) / 60 ))
        fi

        echo "$COUNT" > /tmp/monitor_state/fail_count
        {
          echo "alert=$ALERT"
          echo "recovered=$RECOVERED"
          echo "previous=$PREV"
          echo "fail_count=$COUNT"
          echo "duration=$DURATION"
        } >> "$GITHUB_OUTPUT"

    - name: Send Discord Alert
      if: steps.delta.outputs.alert == 'true' || github.event.inputs.force_alert == 'true'
      env:
        DISCORD_WEBHOOK: ${{ secrets.MONITORING_DISCORD_WEBHOOK }}
      run: |
        [[ -z "$DISCORD_WEBHOOK" ]] && echo "No webhook configured" && exit 0

        SEV="${{ steps.checks.outputs.severity }}"
        RECOVERED="${{ steps.delta.outputs.recovered }}"
        PREV="${{ steps.delta.outputs.previous }}"
        DURATION="${{ steps.delta.outputs.duration }}"
        CERT="${{ steps.checks.outputs.cert_days }}"
        AVG_MS="${{ steps.checks.outputs.avg_ms }}"
        MAX_MS="${{ steps.checks.outputs.max_ms }}"
        AVG_TTFB="${{ steps.checks.outputs.avg_ttfb }}"
        FAILS="${{ steps.checks.outputs.failures }}"
        OK_N="${{ steps.checks.outputs.ok }}"
        TOTAL="${{ steps.checks.outputs.total }}"

        # --- Title ---
        if [[ "$RECOVERED" == "true" ]]; then
          COLOR=3066993
          [[ -n "$DURATION" && "$DURATION" -gt 0 ]] \
            && TITLE="Recovered (was down ${DURATION}m)" || TITLE="Recovered"
        else
          case "$SEV" in
            CRITICAL) COLOR=15158332 ;; MAJOR) COLOR=15105570 ;;
            WARNING)  COLOR=16776960 ;; SLOW)  COLOR=16744192 ;;
            *)        COLOR=3066993  ;;
          esac
          TITLE="$SEV"
          [[ -n "$DURATION" && "$DURATION" -gt 0 ]] && TITLE+=" (${DURATION}m)"
        fi

        # --- Description ---
        DESC="${OK_N}/${TOTAL} endpoints ok"
        (( FAILS > 0 )) && DESC+=" · **${FAILS} failing**"
        DESC+=" · avg ${AVG_MS}ms / peak ${MAX_MS}ms · ttfb ${AVG_TTFB}ms"

        # --- Endpoint fields: diff-highlighted code blocks ---
        # + prefix = green (ok), - prefix = red (fail), no prefix = neutral (slow)
        fmt_endpoints() {
          local raw
          raw=$(jq -r --argjson slow "$SLOW_MS" --arg type "$1" '
            [.[]|select(.type==$type)|
              (if .status != "ok" then "- "
               elif .ms > $slow then "  "
               else "+ " end) +
              ((.name + "            ")[:12]) +
              (if .status != "ok" then .code
               elif .ms > $slow then (.ms|tostring) + "ms  SLOW"
               else (.ms|tostring) + "ms" end)
            ]|join("\n")' /tmp/results.json)
          printf '```diff\n%s\n```' "$raw"
        }
        PAGES=$(fmt_endpoints page)
        APIS=$(fmt_endpoints api)

        # --- Infrastructure from health response ---
        INFRA="_No health data_"
        HB=/tmp/body_health
        if [[ -f "$HB" ]] && jq -e .checks "$HB" &>/dev/null; then
          INFRA=$(jq -r '
            [
              # Per-database status with latency
              "DB: " + ([.checks.database.connections | to_entries[] |
                (.key | ascii_upcase) + " " + .value.status +
                (if .value.connect_time_ms then " (" + (.value.connect_time_ms|tostring) + "ms)" else "" end)
              ] | join(" · ")),

              # Blocking sessions
              (if (.checks.database.connections.adl.blocking_sessions // 0) > 0 then
                "Blocking: " + (.checks.database.connections.adl.blocking_sessions|tostring) + " sessions"
              else empty end),

              # FPM worker pool
              (if .checks.php_fpm.total_workers then
                "FPM: " + (.checks.php_fpm.active_workers|tostring) + "/" +
                (.checks.php_fpm.total_workers|tostring) + " workers" +
                (if (.checks.php_fpm.listen_queue // 0) > 0
                 then " (queue: " + (.checks.php_fpm.listen_queue|tostring) + ")" else "" end)
              else empty end),

              # Daemons — list names of any that are down
              "Daemons: " + (.checks.daemons.running_count|tostring) + "/" +
                (.checks.daemons.total_count|tostring) +
                (if .checks.daemons.status != "healthy" then " — " +
                  ([.checks.daemons.daemons | to_entries[] |
                    select(.value.status != "running") |
                    .key | gsub("_daemon$";"")] | join(", ")) + " down"
                else "" end),

              # Memory with GB breakdown
              "Memory: " + (.checks.memory.system_used_pct // "?" | tostring) + "%" +
                (if .checks.memory.system_used_mb and .checks.memory.system_total_mb then
                  " (" + ((.checks.memory.system_used_mb / 1024 * 10 | round) / 10 | tostring) + "/" +
                  ((.checks.memory.system_total_mb / 1024 * 10 | round) / 10 | tostring) + " GB)"
                else "" end),

              # Log errors
              (if (.checks.logs.error_count // 0) > 0 then
                "Log errors: " + (.checks.logs.error_count|tostring) + " recent"
              else empty end)
            ] | join("\n")
          ' "$HB")

          # SSL
          if [[ -n "$CERT" ]]; then
            INFRA+=$'\n'"SSL: ${CERT} days"
            (( CERT < 14 )) && INFRA+=" (expiring soon)"
          fi
        fi

        # --- Traffic from stats + realtime response bodies ---
        NL=$'\n'
        TRAFFIC="_No flight data_"
        BS=/tmp/body_stats
        BR=/tmp/body_realtime

        if [[ -f "$BS" ]] && jq -e .global "$BS" &>/dev/null; then
          TOTAL_F=$(jq -r '.global.total//0' "$BS")
          DD=$(jq -r '.global.domestic_to_domestic//0' "$BS")
          DI=$(jq -r '.global.domestic_to_intl//0' "$BS")
          ID=$(jq -r '.global.intl_to_domestic//0' "$BS")
          II=$(jq -r '.global.intl_to_intl//0' "$BS")
          TRAFFIC="${TOTAL_F} flights (D-D ${DD} / D-I ${DI} / I-D ${ID} / I-I ${II})"
        fi

        if [[ -f "$BR" ]] && jq -e .data.by_phase "$BR" &>/dev/null; then
          ENR=$(jq -r '.data.by_phase.enroute//0' "$BR")
          DEP=$(jq -r '.data.by_phase.departed//0' "$BR")
          DSC=$(jq -r '.data.by_phase.descending//0' "$BR")
          TXI=$(jq -r '.data.by_phase.taxiing//0' "$BR")
          TRAFFIC+="${NL}Enroute ${ENR} · Departed ${DEP} · Desc ${DSC} · Taxi ${TXI}"

          TMI_N=$(jq -r '.data.tmi_affected//0' "$BR")
          TMI_D=$(jq -r '.data.avg_tmi_delay_min//0' "$BR")
          (( TMI_N > 0 )) && TRAFFIC+="${NL}TMI: ${TMI_N} affected, avg ${TMI_D}m delay"
        fi

        # --- Build and send ---
        LOGS="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

        jq -n \
          --arg title "PERTI Monitor — $TITLE" --argjson color "$COLOR" \
          --arg desc "$DESC" \
          --arg pages "$PAGES" --arg apis "$APIS" \
          --arg infra "$INFRA" --arg traffic "$TRAFFIC" \
          --arg prev "$PREV" --arg sev "${TITLE%% (*}" --arg logs "$LOGS" \
          --arg ts "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
          '{embeds:[{
            title: $title,
            description: $desc,
            color: $color,
            fields: [
              {name: "Pages",          value: $pages, inline: true},
              {name: "APIs",           value: $apis,  inline: true},
              {name: "\u200b",         value: "\u200b", inline: false},
              {name: "Infrastructure", value: $infra, inline: true},
              {name: "Traffic",         value: $traffic, inline: true},
              {name: "\u200b",         value: ($prev + " \u2192 **" + $sev + "** \u00b7 [View run](" + $logs + ")"), inline: false}
            ],
            footer: {text: "External Monitor"},
            timestamp: $ts
          }]}' \
        | curl -sS -X POST -H "Content-Type: application/json" -d @- "$DISCORD_WEBHOOK"

    - name: Fail on Critical
      if: steps.checks.outputs.severity == 'CRITICAL'
      run: exit 1
